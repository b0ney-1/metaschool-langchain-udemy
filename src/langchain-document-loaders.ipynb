{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loaders and Text Splitters in LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **File Loaders**: For loading local files (CSV, PDF, TXT, etc.)\n",
    "2. **Web Loaders**: For loading content from web sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Text Splitting\n",
    "\n",
    "- RecursiveCharacterTextSplitter\n",
    "- CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Number of characters per chunk\n",
    "    chunk_overlap=50,  # Number of overlapping characters\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "print(\"Text splitter initialized with chunk size of 500 and overlap of 50 characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Loader Example: CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 documents\n",
      "Created 100 splits\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_csv():\n",
    "    # Initialize the CSV loader\n",
    "    loader = CSVLoader(\n",
    "        file_path=\"customers-100.csv\",\n",
    "        csv_args={\n",
    "            'delimiter': ',',\n",
    "            'quotechar': '\"',\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Load the documents\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(splits)} splits\")\n",
    "    \n",
    "    # Take first few chunks to stay within token limits\n",
    "    limited_splits = splits[:5]\n",
    "    \n",
    "    return \"\\n\\n\".join([doc.page_content for doc in limited_splits])\n",
    "\n",
    "context = load_and_process_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is sheryl's email address?\n",
      "Answer:  zunigavanessa@smith.info\n"
     ]
    }
   ],
   "source": [
    "def setup_qa_chain():\n",
    "    # Initialize OpenAI model\n",
    "    llm = OpenAI(temperature=0)\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"Based on the following customer data, please answer the question.\n",
    "        \n",
    "        Customer Data:\n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Answer: \"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    return prompt | llm\n",
    "\n",
    "# Set up the chain\n",
    "qa_chain = setup_qa_chain()\n",
    "\n",
    "# Test with a sample question\n",
    "question = \"What is sheryl's email address?\"\n",
    "response = qa_chain.invoke({\"context\": context, \"question\": question})\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Loader Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bones\\Projects\\Udemy\\metaschool-langchain-udemy\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded webpage with 1 documents\n",
      "Created 42 splits\n",
      "\n",
      "Question: What is LangChain?\n",
      "Answer: LangChain is a language learning platform that offers courses in 8 different languages: Persian, Korean, Hindi, Japanese, Portuguese, Thai, Turkish, and Chinese. It provides tools and resources for users to improve their language skills and offers a variety of features such as interactive lessons, vocabulary building exercises, and cultural insights. LangChain aims to make language learning accessible and enjoyable for all users.\n",
      "\n",
      "Question: What are the main features of LangChain?\n",
      "Answer: \n",
      "1. Multilingual Support: LangChain supports 8 different languages, making it accessible to a wide range of users.\n",
      "\n",
      "2. Translation Tools: LangChain offers various translation tools, such as machine translation and human translation, to help users accurately translate content.\n",
      "\n",
      "3. Collaboration: LangChain allows for collaboration between users, making it easier to work on translations and share resources.\n",
      "\n",
      "4. History: LangChain keeps a record of all translations and edits, allowing users to track changes and revert to previous versions if needed.\n",
      "\n",
      "5. References: LangChain provides a section for references, allowing users to cite sources and ensure accuracy in translations.\n",
      "\n",
      "6. External Links: LangChain includes a section for external links, providing users with additional resources and information.\n",
      "\n",
      "7. Customization: LangChain allows users to customize their experience by choosing their preferred language and adjusting settings.\n",
      "\n",
      "8. User-Friendly Interface: LangChain has a user-friendly interface, making it easy for users to navigate and use the translation tools.\n",
      "\n",
      "9. Accessibility: LangChain is accessible on various devices, including desktops, laptops, and mobile devices, making it convenient for users to access and use the platform.\n",
      "\n",
      "10. Constant Updates: LangChain is regularly updated with new features and improvements, ensuring a smooth and efficient translation experience for\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_webpage(url):\n",
    "    # Initialize web loader with custom headers\n",
    "    loader = WebBaseLoader(\n",
    "        url,\n",
    "        verify_ssl=False,\n",
    "        header_template={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Load and process the webpage\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded webpage with {len(documents)} documents\")\n",
    "    \n",
    "    # Split the content\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(splits)} splits\")\n",
    "    \n",
    "    limited_splits = splits[:3]\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in limited_splits])\n",
    "\n",
    "# Test with a sample URL\n",
    "url = \"https://en.wikipedia.org/wiki/LangChain\"\n",
    "web_context = load_and_process_webpage(url)\n",
    "\n",
    "# Test with some questions\n",
    "questions = [\n",
    "    \"What is LangChain?\",\n",
    "    \"What are the main features of LangChain?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    response = qa_chain.invoke({\"context\": web_context, \"question\": question})\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Answer: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
