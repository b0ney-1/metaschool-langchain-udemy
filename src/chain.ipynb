{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodality in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Images and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "import httpx\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Base64 Encoded Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"What season does this image appear to be from?\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = model.invoke([message])\n",
    "print(\"Response using base64 image:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct URL Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Describe the path or walkway in this image.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = model.invoke([message])\n",
    "print(\"Response using direct URL:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prompt Templates with Multimodal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant skilled at analyzing images.\"),\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": \"{question}\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"}},\n",
    "        ],\n",
    "    )\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"question\": \"What are the main colors present in this image?\",\n",
    "    \"image_data\": image_data\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Tools with Multimodal Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "@tool\n",
    "def analyze_weather(weather_details: Dict[str, str]) -> str:\n",
    "    \"\"\"Analyze detailed weather conditions from an image\n",
    "    Args:\n",
    "        weather_details: Dictionary containing weather analysis details\n",
    "    Returns:\n",
    "        str: Detailed weather analysis\n",
    "    \"\"\"\n",
    "    return f\"Weather Analysis: {weather_details['sky_condition']}. \" \\\n",
    "           f\"Time of day appears to be {weather_details['time_of_day']}. \" \\\n",
    "           f\"Visibility is {weather_details['visibility']}.\"\n",
    "\n",
    "model_with_tools = model.bind_tools([analyze_weather])\n",
    "\n",
    "system_message = SystemMessage(content=\"\"\"You are a weather analysis expert. When shown an image:\n",
    "1. Carefully observe the sky conditions, lighting, and visibility\n",
    "2. Use the analyze_weather tool with your observations\n",
    "3. Provide additional context about the weather conditions\n",
    "Be specific and detailed in your analysis.\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_message,\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Please analyze the weather conditions in this image.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Get the response\n",
    "response = model_with_tools.invoke(messages)\n",
    "print(\"\\nAI Analysis:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
